{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dynamic Programming`과 `Reinforcement Learning`의 차이 : RL은 환경의 모델을 몰라도 환경과의 상호작용을 통해 최적 정책을 학습하는 것\n",
    "\n",
    "(**Model Free**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**\n",
    "\n",
    "가치함수를 학습하는 것, 크게 두 가지 방법이 존재\n",
    "\n",
    "- **MonteCarlo** \n",
    "- Temporal-difference (TD)\n",
    "\n",
    "**Control**\n",
    "\n",
    "가치함수를 토대로 정책을 발전시켜 최적 정책을 찾는 것\n",
    "\n",
    "- SARSA\n",
    "- Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강화학습과 정책 평가 1 : Monte-Carlo Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강화학습 과정\n",
    "\n",
    "1. 일단 진행\n",
    "2. 자신 평가\n",
    "3. 평가\n",
    "4. 업데이트\n",
    "\n",
    "5. 1-4 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 강화학습의 예측과 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'Dynamic Programming'`에서의 Policy Iteration 방법 중 `Policy evaluation`은  `bellman expectation equation`을 사용하여 `value function`을 계산하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **bellman expectation equation**\n",
    "> \n",
    "$$\n",
    "\\mathbf{v}_\\pi(\\mathbf{s}) = \\mathbb{E}_\\pi[\\mathbf{R_{t+1}} + \\gamma \\mathbf{v}_\\pi(\\mathbf{S}_{t+1}) \\ | \\ \\mathbf{S}_{t} = \\mathbf{s}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 강화학습에서는 위와 같이 **계산**을 통해서 **`value function`**을 알아내는 것이 아니라 **Agent**가 겪은 경험으로부터 예측하여 **`value function`**(참 값)을 업데이트 함, 많은 강화학습 알고리즘 중에 고전적 방법인 **Monte-Carlo Prediction**를 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte-Carlo Prediction 근사의 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 원의 넓이를 계산하기 위해 원의 방정식을 이용한다.\n",
    "\n",
    "> 원의 넓이를 구하는 방정식\n",
    "$$\n",
    "\\mathbf{S} = \\pi\\mathbf{r}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1)** 하지만, 방정식을 모른다면 어떻게 계산할 수 있을까?\n",
    "\n",
    "**A1)** **Monte-Carlo Approximation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Monte-Carlo Approximation` : \"무작위로 무엇인가를 해본다\", \"Sample\"을 통해 \"원래의 값에 대해 이럴 것이다\"라고 추정하는 것, 무작위로 많이하다보면 원래의 값과 비슷해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Example1)** \n",
    "종이 위에 그려진 원의 넓이를 구하려면 어떻게 해야 할까? (단, 종이의 넓이는 $\\mathbf{S(B)}$이고 $\\mathbf{S(B)}$는 이미 안다고 가정)\n",
    "\n",
    "<img src=\"https://github.com/DeepHaeJoong/RL/blob/master/RL_Document/Lecture4_Model-Free%20Prediction/Ch4_1_Monte-Carlo/FIGURE/FIG_1.png?raw=true\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "원이 그려진 종이 위에 점을 무작위로 계속 뿌린다.\n",
    "\n",
    "<img src=\"https://github.com/DeepHaeJoong/RL/blob/master/RL_Document/Lecture4_Model-Free%20Prediction/Ch4_1_Monte-Carlo/FIGURE/FIG_2.png?raw=true\" alt=\"drawing\" width=\"330\"/>\n",
    "\n",
    "$$\n",
    "\\frac{\\mathbf{S(A)}}{\\mathbf{S(B)}} \\sim \\frac{\\mathbf{1}}{\\mathbf{11}} \\sum_{i = 1}^{11} \\mathbf{I(\\text{red_dot}_i \\in \\mathbf{A})} = \\frac{\\mathbf{4}}{\\mathbf{11}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MC 추정은 무한히 반복하면 원래 값과 동일해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "$\n",
    "\\text{if n } \\to \\infty , \\text{then} \\\\\n",
    "\\frac{1}{n} \\sum_{i = 1}^{n} \\mathbf{I(\\text{red_dot}_i \\in \\mathbf{A})} = \\frac{\\mathbf{S(A)}}{\\mathbf{S(B)}}\n",
    "$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "장점 : 근사의 장점은 방정식을 몰라도 원래 값을 추정할 수 있는 점,\n",
    "\n",
    "강화학습에서 MC 근사를 어떻게 사용하는지 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 샘플링과 몬테카를로 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Monte-Carlo Prediction**를 통한 **Value Function** 추정의 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/DeepHaeJoong/RL/blob/master/RL_Document/Lecture4_Model-Free%20Prediction/Ch4_1_Monte-Carlo/FIGURE/FIG_3.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 기존 **state-value function** 정의\n",
    ">\n",
    "$$\n",
    "\\mathbf{v}_\\pi(\\mathbf{s}) = \\mathbb{E}_\\pi[\\mathbf{R_{t+1}} + \\gamma \\mathbf{v}_\\pi(\\mathbf{S}_{t+1}) \\ | \\ \\mathbf{S}_{t} = \\mathbf{s}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Programming에서는 Bellman Expectation Equation을 통해 전체 문제를 작게 쪼개서 풀었지만, **`Sampling`**을 통해 기댓값을 계산하지 않고, \"예측\"하려면 어떻게 해야할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 끝이 있는 `에피소드`에서의 반환값 정의 (한번의 샘플링)\n",
    ">\n",
    "$$\n",
    "\\mathbf{G_t} = \\mathbf{R}_{t+1} + \\gamma\\mathbf{R_{t+2}} + ... + \\gamma^{\\mathbf{T-t+1}}\\mathbf{R_{T}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 번의 에피소드를 통해 반환값을 얻어도 한 번의 에피소드로는 추정이 불가능하다. (비유 : 원의 넓이를 구할 때 점을 한 번 찍는 것과 같음). 따라서, 여러번 에피소드를 통해 각 상태에 대해 모인 반환값들의 평균을 통해 가치함수의 값을 추정해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 계산 가능한 형태의 Bellman Expectation Equation\n",
    ">\n",
    "$$\n",
    "1. \\mathbf{v}_\\pi(\\mathbf{s}) = \\mathbb{E}_\\pi[\\mathbf{R}_{t+1} + \\gamma\\mathbf{R_{t+2}} + ... \\ | \\ \\mathbf{S}_{t} = \\mathbf{s}]\n",
    "$$\n",
    "\n",
    "$$\n",
    "2. \\mathbf{v}_\\pi(\\mathbf{s}) = \\mathbb{E}_\\pi[\\mathbf{R_{t+1}} + \\gamma \\mathbf{v}_\\pi(\\mathbf{S}_{t+1}) \\ | \\ \\mathbf{S}_{t} = \\mathbf{s}]\n",
    "$$\n",
    "\n",
    "$$\n",
    "3. \\mathbf{v}_\\pi(\\mathbf{s}) = \\sum_{\\mathbf{a} \\in A} \\pi(\\mathbf{a}|\\mathbf{s}) \\ (\\mathbf{R_{t+1}} + \\gamma \\sum_{\\mathbf{s'} \\in S} \\mathbf{P_{ss'}^{\\mathbf{a}}} \\mathbf{v}_\\pi(\\mathbf{s'}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 3.에서 환경의 모델인 $\\mathbf{P_{ss'}^{\\mathbf{a}}}$ 와 $\\mathbf{R_{t+1}}$을 알아야 한다. 마치 원의 넓이를 구할 때 원의 넓이의 방정식을 알아야 하는 것과 마찬가지이다. 여기서는 환경의 모델을 몰라도 여러 에피소드를 통해 구한 반환값의 평균을 통해 $\\mathbf{v}_\\pi(\\mathbf{s})$를 추정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $\\mathbf{s}$라는 상태를 방문해서 얻은 반환값들의 평균을 통해 Value Function을 추정하는 식\n",
    "> \n",
    "$$\n",
    "\\mathbf{v}_\\pi(\\mathbf{s}) \\sim \\frac{\\mathbf{1}}{\\mathbf{N(s)}} \\sum_{\\mathbf{i=1}}^{\\mathbf{N(s)}} \\mathbf{G_i(s)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "> 에피소드를 통해 $\\mathbf{s}$를 지나 $\\mathbf{s_T}$ (마침 상태)까지의 반환값들의 평균 (그림)\n",
    "> \n",
    "<img src=\"https://github.com/DeepHaeJoong/RL/blob/master/RL_Document/Lecture4_Model-Free%20Prediction/Ch4_1_Monte-Carlo/FIGURE/FIG_4.png?raw=true\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **업데이트식의 전개 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{V}_{\\mathbf{n+1}} = \\frac{\\mathbf{1}}{\\mathbf{n}} \\sum_{\\mathbf{i=1}}^{\\mathbf{n}} \\mathbf{G_i} = \\frac{\\mathbf{1}}{\\mathbf{n}} (\\mathbf{G_n} + \\sum_{\\mathbf{i=1}}^{\\mathbf{n-1}} \\mathbf{G_i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **업데이트식의 전개 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{V}_{\\mathbf{n+1}} = \\frac{\\mathbf{1}}{\\mathbf{n}} (\\mathbf{G_n} + (\\mathbf{n-1})\\frac{1}{\\mathbf{n-1}}\\sum_{\\mathbf{i=1}}^{\\mathbf{n-1}} \\mathbf{G_i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\qquad \\mathbf{V}_{\\mathbf{n}} = \\frac{1}{\\mathbf{n-1}}\\sum_{\\mathbf{i=1}}^{\\mathbf{n-1}} \\mathbf{G_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **업데이트식의 전개 3**\n",
    ">\n",
    "$$\n",
    "\\mathbf{V}_{\\mathbf{n+1}} = \\frac{\\mathbf{1}}{\\mathbf{n}}(\\mathbf{G_n} + (\\mathbf{n-1})\\mathbf{V}_{\\mathbf{n}})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{V}_{\\mathbf{n+1}} = \\frac{\\mathbf{1}}{\\mathbf{n}}(\\mathbf{G_n} + \\mathbf{n}\\mathbf{V}_{\\mathbf{n}} - \\mathbf{V}_{\\mathbf{n}})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{V}_{\\mathbf{n+1}} = \\mathbf{V}_{\\mathbf{n}} + \\frac{\\mathbf{1}}{\\mathbf{n}}(\\mathbf{G_n} - \\mathbf{V}_{\\mathbf{n}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Monte-Carlo Prediction**에서 **Value Function** 업데이트 식\n",
    ">\n",
    "$$\n",
    "\\mathbf{V(s)} \\leftarrow \\mathbf{V(s)}+ \\frac{\\mathbf{1}}{\\mathbf{n}}(\\mathbf{G(s)} - \\mathbf{V(s)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오차 : $\\mathbf{G(s)} - \\mathbf{V(s)}$\n",
    "- Step Size : $\\frac{\\mathbf{1}}{\\mathbf{n}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Monte-Carlo Prediction**에서 **Value Function** 업데이트의 **일반식**\n",
    ">\n",
    "$$\n",
    "\\mathbf{V(s)} \\leftarrow \\mathbf{V(s)}+ \\alpha(\\mathbf{G(s)} - \\mathbf{V(s)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Monte-Carlo Prediction** 이후의 모든 강화학습 방법에서 **Value Funcation**을 업데이트하는 것은 위의 식을 변형한 것 (이해 중요)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/DeepHaeJoong/RL/blob/master/RL_Document/Lecture4_Model-Free%20Prediction/Ch4_1_Monte-Carlo/FIGURE/FIG_5.png?raw=true\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $\\mathbf{G(s)}$ = 업데이트의 목표\n",
    "2. $\\alpha(\\mathbf{G(s)} - \\mathbf{V(s)})$ = 업데이트의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Agent`**는 위 업데이트 식을 통해 에피소드 동안 경험했던 모든 상태에 대해 가치함수를 업데이트한다.\n",
    "\n",
    "어떠한 가치함수가 업데이트될 수록 가치함수는 현재 정책에 대한 참 가치함수에 수렴해 간다. \n",
    "\n",
    "다음에 다룰 **`Temporal-difference prediction`**방법에서는 업데이트의 목표($\\mathbf{G(s)}$)가 변하고 나머지는 동일!\n",
    "\n",
    "#### Things to do\n",
    "- code 확인 필요 : MonteCarlo Prediction은 Model Free이기 때문에 Pss' 존재하지 않을것으로 예상\n",
    "- code 구현 : ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from environment import Env\n",
    "\n",
    "class MCAgent:\n",
    "    def __init__(self, env):\n",
    "        # 환경에 대한 객체 선억\n",
    "        self.env = env\n",
    "        # 가치함수를 2차원 리스트로 초기화 (5 * 5)\n",
    "        self.value_table = [[0.] * env.width for _ in range(env.height)]\n",
    "        # 상 하 좌 우 동일한 확률로 Poliy 초기화\n",
    "        self.policy_table = [[[0.25, 0.25, 0.25, 0.25]] * env.width for _ in range(env.height)]\n",
    "        # 마침 상태의 설정\n",
    "        self.policy_table[2][2] = []\n",
    "        # 감가율\n",
    "        self.discount_facotr = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "image \"pyimage10\" doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f0ad89c8e1e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#agent = MCAgent(actions=list(range(env.n_actions)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#agent = MCIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\RL\\RL_Document\\Lecture4_Model-Free Prediction\\Ch4_1_Monte-Carlo\\environment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{0}x{1}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHEIGHT\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mUNIT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHEIGHT\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mUNIT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_canvas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\RL\\RL_Document\\Lecture4_Model-Free Prediction\\Ch4_1_Monte-Carlo\\environment.py\u001b[0m in \u001b[0;36m_build_canvas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# 캔버스에 이미지 추가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriangle1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriangle2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\study\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mcreate_image\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m   2487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;34m\"\"\"Create image item with coordinates x1,y1.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m         \u001b[1;34m\"\"\"Create line with coordinates x1,y1,...,xn,yn.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\study\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(self, itemType, args, kw)\u001b[0m\n\u001b[0;32m   2478\u001b[0m         return self.tk.getint(self.tk.call(\n\u001b[0;32m   2479\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'create'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitemType\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2480\u001b[1;33m             *(args + self._options(cnf, kw))))\n\u001b[0m\u001b[0;32m   2481\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_arc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m         \u001b[1;34m\"\"\"Create arc shaped region with coordinates x1,y1,x2,y2.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTclError\u001b[0m: image \"pyimage10\" doesn't exist"
     ]
    }
   ],
   "source": [
    "env = Env()\n",
    "#agent = MCAgent(actions=list(range(env.n_actions)))\n",
    "#agent = MCIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from environment import Env\n",
    "\n",
    "\n",
    "# 몬테카를로 에이전트 (모든 에피소드 각각의 샘플로 부터 학습)\n",
    "class MCAgent:\n",
    "    def __init__(self, actions):\n",
    "        self.width = 5\n",
    "        self.height = 5\n",
    "        self.actions = actions\n",
    "        self.learning_rate = 0.01\n",
    "        self.discount_factor = 0.9\n",
    "        self.epsilon = 0.1\n",
    "        self.samples = []\n",
    "        self.value_table = defaultdict(float)\n",
    "\n",
    "    # 메모리에 샘플을 추가\n",
    "    def save_sample(self, state, reward, done):\n",
    "        self.samples.append([state, reward, done])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'actions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-205bc41859c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMCAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'actions'"
     ]
    }
   ],
   "source": [
    "model = MCAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "image \"pyimage13\" doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9ba4fd62cbed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mn_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'u'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'l'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#list(range(env.n_actions))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\RL\\RL_Document\\Lecture4_Model-Free Prediction\\Ch4_1_Monte-Carlo\\environment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{0}x{1}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHEIGHT\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mUNIT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHEIGHT\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mUNIT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_canvas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\RL\\RL_Document\\Lecture4_Model-Free Prediction\\Ch4_1_Monte-Carlo\\environment.py\u001b[0m in \u001b[0;36m_build_canvas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# 캔버스에 이미지 추가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriangle1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriangle2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\study\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mcreate_image\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m   2487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;34m\"\"\"Create image item with coordinates x1,y1.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m         \u001b[1;34m\"\"\"Create line with coordinates x1,y1,...,xn,yn.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\study\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(self, itemType, args, kw)\u001b[0m\n\u001b[0;32m   2478\u001b[0m         return self.tk.getint(self.tk.call(\n\u001b[0;32m   2479\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'create'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitemType\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2480\u001b[1;33m             *(args + self._options(cnf, kw))))\n\u001b[0m\u001b[0;32m   2481\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_arc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m         \u001b[1;34m\"\"\"Create arc shaped region with coordinates x1,y1,x2,y2.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTclError\u001b[0m: image \"pyimage13\" doesn't exist"
     ]
    }
   ],
   "source": [
    "env = Env()\n",
    "n_actions = ['u', 'd', 'l', 'r']\n",
    "#list(range(env.n_actions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
